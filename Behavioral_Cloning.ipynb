{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Behavioral Cloning-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Conv2D, Cropping2D, Lambda, Dense, Flatten\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "from src import get_driving_data, \\\n",
    "    parse_data_row, \\\n",
    "    steering_image_batch_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center image    IMG/center_2018_10_20_21_50_37_206.jpg\n",
      "Left image        IMG/left_2018_10_20_21_50_37_206.jpg\n",
      "Right image      IMG/right_2018_10_20_21_50_37_206.jpg\n",
      "Steering                                     -0.122066\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join('/home', 'Simulation_Data')\n",
    "log_csv = os.path.join(data_dir, 'driving_log.csv')\n",
    "\n",
    "driving_df = get_driving_data(log_csv)\n",
    "print(driving_df.loc[5])  # print random example to check that data is as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of steering angles recorded: 9742 x 3 = 29226\n",
      "mean steering angle: -0.0011161202688359676\n"
     ]
    }
   ],
   "source": [
    "n_samples = driving_df.shape[0]\n",
    "mean_steering = driving_df['Steering'].mean()\n",
    "print(f'number of steering angles recorded: {n_samples} x 3 = {n_samples*3}\\nmean steering angle: {mean_steering}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and validation sets from driving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation dataset\n",
    "train_set, validation_set = train_test_split(driving_df.values, test_size=0.2)\n",
    "\n",
    "train_generator = steering_image_batch_generator(data_dir, train_set)\n",
    "validation_generator = steering_image_batch_generator(data_dir, validation_set)\n",
    "\n",
    "# Also create a smaller training and validation dataset for testing models\n",
    "small_train_set, small_validation_set = train_test_split(driving_df[:1000].values, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PilotNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_image (InputLayer)     (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "image_cropping (Cropping2D)  (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "image_normalization (Lambda) (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 31, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 14, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 5, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 3, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 1, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 100)               211300    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "output_angle (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
     ]
    }
   ],
   "source": [
    "img_height = 160\n",
    "img_width = 320\n",
    "\n",
    "input_layer = Input(shape=(img_height, img_width, 3), name='input_image')\n",
    "\n",
    "# Crop the input image first,\n",
    "# then normalize it.\n",
    "x = Cropping2D(cropping=((70, 25), (0, 0)), name='image_cropping')(input_layer)\n",
    "x = Lambda(lambda n: n / 255.0 - 0.5, name='image_normalization')(x)\n",
    "\n",
    "x = Conv2D(24, (5, 5), strides=(2, 2), activation='relu', name='conv1')(x)\n",
    "x = Conv2D(36, (5, 5), strides=(2, 2), activation='relu', name='conv2')(x)\n",
    "x = Conv2D(48, (5, 5), strides=(2, 2), activation='relu', name='conv3')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', name='conv4')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', name='conv5')(x)\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(100, name='dense1')(x)\n",
    "x = Dense(50, name='dense2')(x)\n",
    "x = Dense(10, name='dense3')(x)\n",
    "x = Dense(1, name='output_angle')(x)\n",
    "\n",
    "model = Model(input=input_layer, output=x)\n",
    "model.compile(loss='mse', optimizer='Nadam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_log_dir(base_path='./logs/PilotNet', path_suffix=None):\n",
    "    localtime = time.localtime()\n",
    "    datetime_string = time.strftime(\"%Y-%m-%d_%H-%M-%S\", localtime)\n",
    "    if path_suffix is not None:\n",
    "        return f'{base_path}/{path_suffix}/{datetime_string}'\n",
    "    return f'{base_path}/{datetime_string}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 2s 4ms/step - loss: 1.0920 - val_loss: 0.0031\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 8.2441e-04 - val_loss: 9.7478e-04\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 7.5267e-04 - val_loss: 8.3875e-04\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 6.8166e-04 - val_loss: 6.8388e-04\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 8.4787e-04 - val_loss: 9.9316e-04\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 6.9171e-04 - val_loss: 8.4077e-04\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdae00e34a8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, steering = [], []\n",
    "for row in small_train_set:\n",
    "    i, s = parse_data_row(data_dir, row)\n",
    "    images.append(i)\n",
    "    steering.append(s)\n",
    "x_train, y_train = np.array(images), np.array(steering)\n",
    "\n",
    "images, steering = [], []\n",
    "for row in small_validation_set:\n",
    "    i, s = parse_data_row(data_dir, row)\n",
    "    images.append(i)\n",
    "    steering.append(s)\n",
    "x_validation, y_validation = np.array(images), np.array(steering)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=get_log_dir(path_suffix='/debug'),\n",
    "                          batch_size=32,\n",
    "                          write_images=True,\n",
    "                          write_graph=True,\n",
    "                          write_grads=True,\n",
    "                          histogram_freq=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_validation, y_validation),\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[tensorboard, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'image_cropping'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(x_train[None, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir=get_log_dir(),\n",
    "                                  batch_size=self.batch_size,\n",
    "                                  write_graph=False)\n",
    "# Save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint('PilotNet.h5', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch=num_train_samples,\n",
    "                    validation_steps=num_validation_samples,\n",
    "                    callbacks=[tensorboard, checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception - transfer learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "\n",
    "model = Xception(weights='imagenet',\n",
    "                 include_top=False,\n",
    "                 input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Freeze all layers of pre-trained model\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1)(x)  # Regression output layer\n",
    "\n",
    "model_final = Model(input=model.input, output=x)\n",
    "model_final.compile(loss='mse', optimizer='Nadam')\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint('Xception_steering.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(train_generator, \n",
    "                          samples_per_epoch=len(train_samples), \n",
    "                          validation_data=validation_generator,\n",
    "                          nb_val_samples=len(validation_samples), \n",
    "                          nb_epoch=10, \n",
    "                          callbacks=[checkpoint, early])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
